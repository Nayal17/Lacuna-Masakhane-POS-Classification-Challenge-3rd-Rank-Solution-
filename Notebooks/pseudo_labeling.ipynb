{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:01.081536Z","iopub.status.busy":"2023-09-17T10:37:01.081180Z","iopub.status.idle":"2023-09-17T10:37:01.087482Z","shell.execute_reply":"2023-09-17T10:37:01.086273Z","shell.execute_reply.started":"2023-09-17T10:37:01.081504Z"},"trusted":true},"outputs":[],"source":["!pip install -q transformers\n","!pip install -q sentencepiece\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:01.857027Z","iopub.status.busy":"2023-09-17T10:37:01.856006Z","iopub.status.idle":"2023-09-17T10:37:13.500292Z","shell.execute_reply":"2023-09-17T10:37:13.499162Z","shell.execute_reply.started":"2023-09-17T10:37:01.856985Z"},"trusted":true},"outputs":[],"source":["import os \n","import gc\n","import re\n","import math\n","import random\n","import warnings\n","import numpy as np\n","import pandas as pd\n","\n","\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig,\n","    AutoModel,\n","    AutoModelForTokenClassification,\n","    get_cosine_schedule_with_warmup,\n",")\n","\n","from tqdm.notebook import tqdm\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:13.503318Z","iopub.status.busy":"2023-09-17T10:37:13.502527Z","iopub.status.idle":"2023-09-17T10:37:13.515923Z","shell.execute_reply":"2023-09-17T10:37:13.514804Z","shell.execute_reply.started":"2023-09-17T10:37:13.503278Z"},"trusted":true},"outputs":[],"source":["class cfg:\n","    seed = 2023\n","    epochs = 2\n","    batch_size = 4\n","    max_grad_norm = 1\n","    learning_rate = 1e-5\n","    weight_decay = 1e-4\n","    adam_epsilon = 1e-8\n","    ls = 0.01\n","    num_cycles = 0.5\n","    max_length = 180\n","    max_sentences = 20000 # max possible is around 1500, above that means consider all sentences\n","    device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n","    val = False\n","    \n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=cfg.seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:13.518380Z","iopub.status.busy":"2023-09-17T10:37:13.517060Z","iopub.status.idle":"2023-09-17T10:37:13.576943Z","shell.execute_reply":"2023-09-17T10:37:13.575848Z","shell.execute_reply.started":"2023-09-17T10:37:13.517375Z"},"trusted":true},"outputs":[],"source":["test_data_labels = pd.read_csv('/content/pseudo_round2.csv') # update pseudo labels every round\n","test_data_labels.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:13.580842Z","iopub.status.busy":"2023-09-17T10:37:13.580046Z","iopub.status.idle":"2023-09-17T10:37:13.636887Z","shell.execute_reply":"2023-09-17T10:37:13.635586Z","shell.execute_reply.started":"2023-09-17T10:37:13.580802Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv(\"/content/Test.csv\")\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:13.639231Z","iopub.status.busy":"2023-09-17T10:37:13.638806Z","iopub.status.idle":"2023-09-17T10:37:13.701060Z","shell.execute_reply":"2023-09-17T10:37:13.699993Z","shell.execute_reply.started":"2023-09-17T10:37:13.639193Z"},"trusted":true},"outputs":[],"source":["test_df.shape\n","test_df_to_concat = test_df[['Id','Word','Language']].merge(test_data_labels,how='left',on='Id')\n","print(test_df_to_concat.shape)\n","test_df_to_concat = test_df_to_concat.rename(columns = {'Language':'lang','Word':'word','Pos':'tag'})\n","test_df_to_concat.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:13.704379Z","iopub.status.busy":"2023-09-17T10:37:13.702658Z","iopub.status.idle":"2023-09-17T10:37:14.174457Z","shell.execute_reply":"2023-09-17T10:37:14.173430Z","shell.execute_reply.started":"2023-09-17T10:37:13.704333Z"},"trusted":true},"outputs":[],"source":["# train.csv has train data of all languages under one file\n","train_df = pd.read_csv(\"/content/train.csv\")\n","train_df = pd.read_csv(\"/content/train.csv\")\n","print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:14.176924Z","iopub.status.busy":"2023-09-17T10:37:14.176160Z","iopub.status.idle":"2023-09-17T10:37:14.478127Z","shell.execute_reply":"2023-09-17T10:37:14.477065Z","shell.execute_reply.started":"2023-09-17T10:37:14.176884Z"},"trusted":true},"outputs":[],"source":["train_df = pd.concat([train_df,test_df_to_concat])\n","print(train_df.shape)\n","test_df = pd.read_csv(\"/content/Test.csv\")\n","train_df = train_df[train_df.word.notnull()]\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:14.481838Z","iopub.status.busy":"2023-09-17T10:37:14.481511Z","iopub.status.idle":"2023-09-17T10:37:14.519438Z","shell.execute_reply":"2023-09-17T10:37:14.518197Z","shell.execute_reply.started":"2023-09-17T10:37:14.481801Z"},"trusted":true},"outputs":[],"source":["train_df.Id.isna().sum()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:14.522369Z","iopub.status.busy":"2023-09-17T10:37:14.520983Z","iopub.status.idle":"2023-09-17T10:37:14.585588Z","shell.execute_reply":"2023-09-17T10:37:14.584513Z","shell.execute_reply.started":"2023-09-17T10:37:14.522340Z"},"trusted":true},"outputs":[],"source":["train_df.lang.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:14.589806Z","iopub.status.busy":"2023-09-17T10:37:14.589492Z","iopub.status.idle":"2023-09-17T10:37:14.605476Z","shell.execute_reply":"2023-09-17T10:37:14.604174Z","shell.execute_reply.started":"2023-09-17T10:37:14.589761Z"},"trusted":true},"outputs":[],"source":["langs = ['pcm','hau', 'bbj', 'ewe', 'bam', 'zul', 'lug', 'nya', 'yor',\n","       'wol', 'sna', 'ibo', 'xho', 'fon', 'swa', 'twi', 'kin', 'mos',\n","        'luo','tsn']\n","\n","label_vocab = {'PAD': -100, 'ADJ': 0, 'ADP': 1, 'ADV': 2, 'AUX': 3, 'CCONJ': 4, 'DET': 5,\\\n","               'INTJ': 6, 'NOUN': 7, 'NUM': 8, 'PART': 9,\\\n","               'PRON': 10, 'PROPN': 11, 'PUNCT': 12, 'SCONJ': 13, 'SYM': 14, 'VERB': 15, 'X': 16}\n","\n","print(f\"Total languages: {len(langs)}   Total tags: {len(label_vocab)-1}\")\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:14.608187Z","iopub.status.busy":"2023-09-17T10:37:14.607126Z","iopub.status.idle":"2023-09-17T10:37:14.638259Z","shell.execute_reply":"2023-09-17T10:37:14.637285Z","shell.execute_reply.started":"2023-09-17T10:37:14.608139Z"},"trusted":true},"outputs":[],"source":["if cfg.val: \n","    train_data = train_df[~train_df['lang'].isin(['swa'])] \n","    val_data = train_df[train_df['lang'].isin(['swa'])]\n","    \n","else:\n","    train_data = train_df.copy()"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:14.640223Z","iopub.status.busy":"2023-09-17T10:37:14.639805Z","iopub.status.idle":"2023-09-17T10:37:55.966478Z","shell.execute_reply":"2023-09-17T10:37:55.965421Z","shell.execute_reply.started":"2023-09-17T10:37:14.640187Z"},"trusted":true},"outputs":[],"source":["def get_samples(df, full_val_samples=False):\n","    sentences = []\n","    taggings = []\n","\n","    # Temporary variables to store sentence and tagging for current sentence\n","    current_sentence = []\n","    current_tagging = []\n","    \n","    for lang in tqdm(df.lang.unique(), total=len(df.lang.unique())):\n","        sentence_count = 0\n","        # Process each row in the CSV data\n","        for index, row in df[df.lang==lang].iterrows():\n","            word = row['word']\n","            tag = row['tag']\n","\n","            # removing soft hyphens\n","            word = word.replace('\\x8d', '')\n","\n","\n","            current_sentence.append(word)\n","            current_tagging.append(tag)\n","\n","            if word.strip() in ['.', '?', '!']:\n","                sentence_count+=1\n","                assert len(current_sentence)==len(current_tagging)\n","                sentences.append(current_sentence)\n","                taggings.append(current_tagging)\n","                current_sentence = []\n","                current_tagging = []\n","\n","\n","\n","    return sentences, taggings\n","\n","t_sentences, t_taggings = get_samples(train_data)\n","if cfg.val:\n","    v_sentences, v_taggings = get_samples(val_data, full_val_samples=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:55.968632Z","iopub.status.busy":"2023-09-17T10:37:55.968022Z","iopub.status.idle":"2023-09-17T10:37:56.035345Z","shell.execute_reply":"2023-09-17T10:37:56.034290Z","shell.execute_reply.started":"2023-09-17T10:37:55.968597Z"},"trusted":true},"outputs":[],"source":["def rem_duplicates(t_sentences, t_taggings):\n","    sentence_dict = {}\n","    \n","    unique_sentences = []\n","    unique_taggings = []\n","    \n","    for index, s in enumerate(t_sentences):\n","        joined = \" \".join(s)\n","        \n","        if joined not in sentence_dict:\n","            sentence_dict[joined] = index\n","            \n","            unique_sentences.append(s)\n","            unique_taggings.append(t_taggings[index])\n","    \n","    return unique_sentences, unique_taggings\n","\n","\n","print(f\"Total Sentences: {len(t_sentences)}\")\n","\n","t_sentences, t_taggings = rem_duplicates(t_sentences, t_taggings)\n","\n","print(f\"Unique Sentences: {len(t_sentences)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:56.039630Z","iopub.status.busy":"2023-09-17T10:37:56.036639Z","iopub.status.idle":"2023-09-17T10:37:56.046779Z","shell.execute_reply":"2023-09-17T10:37:56.045503Z","shell.execute_reply.started":"2023-09-17T10:37:56.039601Z"},"trusted":true},"outputs":[],"source":["def align_tokenizations(sentences, taggings, tokenizer):\n","    tokenized_sentences = []\n","    aligned_taggings = []\n","    for sentence, tagging in tqdm(zip(sentences, taggings), total=len(sentences)):\n","        tok_sent = []\n","        tags = []\n","        \n","        for word, tag in zip(sentence, tagging):\n","            word_tokens = tokenizer.tokenize(word)\n","            tok_sent.extend(word_tokens)\n","            tag = [tag] + ['PAD'] * (len(word_tokens) - 1)\n","            tags.extend(tag)\n","            \n","        tokenized_sentences.append(tok_sent)\n","        aligned_taggings.append(tags)\n","        assert len(tok_sent) == len(tags)\n","\n","    return tokenized_sentences, aligned_taggings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:56.049062Z","iopub.status.busy":"2023-09-17T10:37:56.048289Z","iopub.status.idle":"2023-09-17T10:37:56.058866Z","shell.execute_reply":"2023-09-17T10:37:56.057864Z","shell.execute_reply.started":"2023-09-17T10:37:56.049004Z"},"trusted":true},"outputs":[],"source":["def convert_to_ids(sentences, taggings, tokenizer):\n","    sentences_ids = []\n","    taggings_ids = []\n","    for i, (sentence, tagging) in tqdm(enumerate(zip(sentences, taggings)), total=len(sentences)):\n","        sentence_tensor = torch.tensor(tokenizer.convert_tokens_to_ids(['<s>'] + sentence[:cfg.max_length-2] + ['</s>'])).long()\n","        tagging_tensor = torch.tensor([label_vocab['PAD']] + [label_vocab[tag] for tag in tagging[:cfg.max_length-2]] + [label_vocab['PAD']]).long()\n","\n","        sentences_ids.insert(i, sentence_tensor)\n","        taggings_ids.insert(i, tagging_tensor)\n","        \n","\n","\n","        assert len(sentence_tensor) == len(tagging_tensor)\n","    return sentences_ids, taggings_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:37:56.061051Z","iopub.status.busy":"2023-09-17T10:37:56.060495Z","iopub.status.idle":"2023-09-17T10:37:56.076245Z","shell.execute_reply":"2023-09-17T10:37:56.075116Z","shell.execute_reply.started":"2023-09-17T10:37:56.061016Z"},"trusted":true},"outputs":[],"source":["class PosTaggingDataset(Dataset):\n","    def __init__(self, sentences, taggings):\n","        assert len(sentences) == len(taggings)\n","        self.sentences = sentences\n","        self.taggings = taggings\n","\n","    def __getitem__(self, i):\n","        return self.sentences[i], self.taggings[i]\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","def collate_fn(items):\n","    max_len = max(len(item[0]) for item in items) \n","    sentences = torch.ones((len(items), max_len)).long()\n","    taggings = torch.ones((len(items), max_len)).long()\n","    attention_mask = torch.zeros((len(items), max_len)).long()\n","    for i, (sentence, tagging) in enumerate(items):\n","        tagging = torch.tensor([tag for tag in tagging]+[label_vocab['PAD']]*(max_len-len(tagging)))\n","        mask = torch.tensor([1 for s in sentence]).long()\n","        \n","        sentences[i][:len(sentence)] = sentence\n","        taggings[i][:len(tagging)] = tagging\n","        attention_mask[i][:len(mask)] = mask\n","\n","    return {\n","        \"input_ids\": sentences , \n","        \"labels\": taggings, \n","        \"attention_mask\": attention_mask\n","    }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:38:30.144767Z","iopub.status.busy":"2023-09-17T10:38:30.144411Z","iopub.status.idle":"2023-09-17T10:38:30.152534Z","shell.execute_reply":"2023-09-17T10:38:30.151266Z","shell.execute_reply.started":"2023-09-17T10:38:30.144739Z"},"trusted":true},"outputs":[],"source":["class POSModel(nn.Module):\n","    def __init__(self, model_name, model_config, num_labels):\n","        super().__init__()\n","        self.model_config = model_config.update(\n","            {\n","                \"hidden_dropout_prob\": 0.,\n","                \"hidden_dropout\" : 0.,\n","                \"attention_dropout\" : 0.,\n","                \"attention_probs_dropout_prob\" : 0.,\n","                \"add_pooling_layer\": False,\n","            }\n","        )\n","        self.base_model = AutoModel.from_pretrained(model_name, config=self.model_config)     \n","        self.linear = nn.Linear(self.base_model.config.hidden_size, num_labels)\n","            \n","    def forward(self, input_ids, attention_mask):\n","        word_emb, sent_emb = self.base_model(input_ids, attention_mask, return_dict=False) \n","        logits = self.linear(word_emb)\n","        return logits\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:38:30.744238Z","iopub.status.busy":"2023-09-17T10:38:30.743515Z","iopub.status.idle":"2023-09-17T10:38:30.758874Z","shell.execute_reply":"2023-09-17T10:38:30.757865Z","shell.execute_reply.started":"2023-09-17T10:38:30.744200Z"},"trusted":true},"outputs":[],"source":["def train(model, loader, optimizer, scheduler, grad_clip=True):\n","    model.train()\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=True)\n","    criterion = nn.CrossEntropyLoss(label_smoothing=cfg.ls)\n","    total_loss = correct = num_loss = num_perf = 0\n","    for batch in tqdm(loader, total=len(loader)):\n","        with torch.cuda.amp.autocast(enabled=True):\n","            logits = model(batch['input_ids'].to(cfg.device), batch['attention_mask'].to(cfg.device))\n","        \n","        y = batch['labels'].to(cfg.device)\n","        loss = criterion(logits.view(-1, len(label_vocab)-1), y.view(-1))\n","        total_loss += loss.item()\n","        num_loss += 1\n","        scaler.scale(loss).backward()\n","\n","        if grad_clip:\n","            nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n","\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","        scheduler.step()\n","\n","        y_pred = torch.max(logits, 2)[1] # compute highest-scoring tag\n","        mask = (y != label_vocab['PAD']) # ignore <pad> tags\n","        correct += torch.sum((y_pred == y) * mask) # compute number of correct predictions\n","        num_perf += torch.sum(mask).item()\n","\n","    return total_loss / num_loss, correct.item() / num_perf\n","\n","def validate(model, loader):\n","    model.eval()\n","    criterion = nn.CrossEntropyLoss(label_smoothing=cfg.ls)\n","\n","    total_loss = correct = num_loss = num_perf = 0\n","    for batch in loader:\n","        with torch.no_grad():\n","            logits = model(batch['input_ids'].to(cfg.device), batch['attention_mask'].to(cfg.device))\n","        \n","        y = batch['labels'].to(cfg.device)\n","        loss = criterion(logits.view(-1, len(label_vocab)-1), y.view(-1))\n","        total_loss += loss.item()\n","        num_loss += 1\n","\n","        y_pred = torch.max(logits, 2)[1] # compute highest-scoring tag\n","        mask = (y != label_vocab['PAD']) # ignore <pad> tags\n","        correct += torch.sum((y_pred == y) * mask) # compute number of correct predictions\n","        num_perf += torch.sum(mask).item()\n","\n","    return total_loss / num_loss, correct.item() / num_perf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:38:31.338559Z","iopub.status.busy":"2023-09-17T10:38:31.337676Z","iopub.status.idle":"2023-09-17T10:38:31.346840Z","shell.execute_reply":"2023-09-17T10:38:31.345642Z","shell.execute_reply.started":"2023-09-17T10:38:31.338512Z"},"trusted":true},"outputs":[],"source":["def opt_and_sched(model):\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": cfg.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","    optimizer = torch.optim.AdamW(optimizer_grouped_parameters,lr=cfg.learning_rate, eps=cfg.adam_epsilon)\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=cfg.num_warmup_steps,\\\n","                                num_training_steps=cfg.num_train_steps, num_cycles=cfg.num_cycles)\n","\n","    return optimizer, scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:38:32.306484Z","iopub.status.busy":"2023-09-17T10:38:32.306090Z","iopub.status.idle":"2023-09-17T10:38:32.318347Z","shell.execute_reply":"2023-09-17T10:38:32.317128Z","shell.execute_reply.started":"2023-09-17T10:38:32.306455Z"},"trusted":true},"outputs":[],"source":["def fit(model, model_name, train_loader=None, val_loader=None):\n","    cfg.epoch_steps = len(train_loader)\n","    cfg.num_train_steps = cfg.epochs * cfg.epoch_steps\n","    cfg.num_warmup_steps = 0.1 * cfg.epoch_steps \n","\n","    optimizer, scheduler = opt_and_sched(model)\n","    output_model_name = model_name.split(\"/\")[-1] \n","    best_score = 0\n","    for epoch in range(cfg.epochs):\n","        print(\"#\"*30 + f\" Epoch {epoch+1} Running \" + \"#\"*30 + \"\\n\")\n","        train_loss, train_acc = train(model, train_loader, optimizer, scheduler, grad_clip=True)\n","\n","        if cfg.val:\n","            val_loss, val_acc = validate(model, val_loader)\n","\n","        print((\"#\"*20 + f\"Train Loss: {train_loss} | Train Acc: {train_acc} \" + \"#\"*20))\n","        if cfg.val:\n","            print((\"#\"*20 + f\"Val Loss: {val_loss} | Val Acc: {val_acc} \" + \"#\"*20))\n","\n","            if val_acc > best_score:\n","                best_score = val_acc\n","                torch.save(model.state_dict(),f\"./best_epoch.pth\")\n","\n","        else:\n","            if train_acc > best_score:\n","                best_score = train_acc\n","                torch.save(model.state_dict(),f\"./best_epoch.pth\")\n","                \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:38:33.285065Z","iopub.status.busy":"2023-09-17T10:38:33.284401Z","iopub.status.idle":"2023-09-17T10:38:34.105470Z","shell.execute_reply":"2023-09-17T10:38:34.104509Z","shell.execute_reply.started":"2023-09-17T10:38:33.285029Z"},"trusted":true},"outputs":[],"source":["model_name=\"/content/mlm_model\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model_config = AutoConfig.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:38:34.107726Z","iopub.status.busy":"2023-09-17T10:38:34.107334Z","iopub.status.idle":"2023-09-17T10:39:13.305865Z","shell.execute_reply":"2023-09-17T10:39:13.304659Z","shell.execute_reply.started":"2023-09-17T10:38:34.107688Z"},"trusted":true},"outputs":[],"source":["train_tokenized_sentences, train_aligned_taggings = align_tokenizations(t_sentences, t_taggings, tokenizer)\n","train_sentences_ids, train_taggings_ids = convert_to_ids(train_tokenized_sentences, train_aligned_taggings, tokenizer)\n","train_loader = DataLoader(PosTaggingDataset(train_sentences_ids, train_taggings_ids), collate_fn=collate_fn, batch_size=cfg.batch_size, shuffle=True)\n","\n","if cfg.val:\n","    val_tokenized_sentences, val_aligned_taggings = align_tokenizations(v_sentences, v_taggings, tokenizer)\n","    val_sentences_ids, val_taggings_ids = convert_to_ids(val_tokenized_sentences, val_aligned_taggings, tokenizer)\n","    val_loader = DataLoader(PosTaggingDataset(val_sentences_ids, val_taggings_ids), collate_fn=collate_fn, batch_size=cfg.batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-17T10:39:13.308410Z","iopub.status.busy":"2023-09-17T10:39:13.308029Z"},"trusted":true},"outputs":[],"source":["model = POSModel(model_name, model_config, len(label_vocab)-1)\n","# model = nn.DataParallel(model, device_ids=[0, 1])\n","model = model.to(cfg.device)\n","\n","if cfg.val:\n","    fit(model, model_name, train_loader, val_loader)\n","\n","    del val_tokenized_sentences, val_aligned_taggings, val_sentences_ids, val_taggings_ids\n","\n","else:\n","    fit(model, model_name, train_loader)\n","\n","del model, tokenizer, model_config\n","del train_tokenized_sentences, train_aligned_taggings, train_sentences_ids, train_taggings_ids\n","\n","for _ in range(5):\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
